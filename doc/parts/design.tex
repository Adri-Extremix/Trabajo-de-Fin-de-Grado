\chapter{Diseño}\label{chap:diseno}

En este capítulo se detalla el diseño que tendrá la solución propuesta. Para ello se discutirán sobre las posibles alternativas y cuál de ellas ha sido elegida (\sectionref{estudio-solucion-final}) y posteriormente, se describirá la arquitectura del sistema (\sectionref{arquitectura-sistema}) en base a la solución final elegida.

\section{Estudio de la solución final}\label{sec:estudio-solucion-final}

Para la realización del estudio de la solución final se han tenido en cuenta los requisitos especificados en \sectionref{requisitos} y las herramientas existentes descritas en \chapterref{estado-del-arte}. 

\subsection{Monolítico vs Distribuido} \label{subsec:monolitico-vs-distribuido}

Durante la especificación de los requisitos se han descrito varios requisitos que influyen en la elección del sistema operativo y de la arquitectura del sistema. En concreto los requisitos \sreqref{NF-abstraccion-so} y \sreqref{NF-abstraccion-arch} especifican que la herramienta debe de tener el mismo funcionamiento aunque la arquitectura del sistema o el sistema operativo sean diferentes. Estos requisitos nos obligan a tomar una decisión respecto a la arquitectura del sistema. 

\subsubsection{Monolítico} \label{subsubsec:monolitico}

Una aplicación monolítica es aquella que se ejecuta en una única máquina y en un único sistema operativo. Este tipo de aplicaciones son más sencillas de desarrollar y de mantener, ya que no requieren de una comunicación entre diferentes máquinas. Sin embargo, una aplicación monolítica no es capaz de ejecutarse en diferentes sistemas operativos, ya que el código fuente debe de ser compilado para cada sistema operativo. Dado que el requisito \sreqref{NF-multiplataforma} indica que el sistema debe de poder ejecutar en cualquier sistema operativo, el monolítico no es una opción viable.

\subsubsection{Distribuido} \label{subsubsec:distribuido}

Una aplicación distribuida es aquella que se ejecuta en múltiples procesos. Este tipo de aplicaciones tienen una mayor complejidad de desarrollar, debido a la comunicación entre procesos. Sin embargo, una aplicación distribuida que sirva un servicio web podría funcionar en cualquier sistema operativo (\sreqref{NF-multiplataforma}, \sreqref{NF-abstraccion-so} y \sreqref{NF-abstraccion-arch}), dado que solo ejecutaría el código del cliente, y además contemplaría el requisito \sreqref{NF-ejecucion-POSIX}, que indica que el sistema debe de ejecutarse en un sistema operativo UNIX para soportar la ejecución de hilos POSIX. Esta arquitectura permitiría tener una única aplicación web que se pueda ejecutar el lado cliente en cualquier sistema operativo y arquitectura, mientras se utiliza un servidor que ejecuta en un sistema operativo UNIX que permita la ejecución de hilos POSIX.

Durante la sección \sectionref{arquitectura-sistema} se detallarán cómo se ha implementado este diseño distribuido. 

\subsection{Depuración} \label{subsec:depuracion}

Para implementar la depuración concurrente existen varias alternativas. 

\subsubsection{Almacenamiento de estados} \label{subsec:almacenamiento-estados}

Para implementar las operaciones básicas de un depurador es necesario moverse por la ejecución del código. Es por esta razón que se evaluó la posibilidad de inyectar código en el programa cuyo propósito sea almacenar el estado de la ejecución en un momento determinado. Con estos estados almacenados el usuario podría moverse entre cada uno de ellos, facilitando el rebobinado de la ejecución.

Para almacenar estos estados sería necesario introducir código en el programa tras cada sentencia que modifique el estado de la ejecución, es decir, creación de variables, modificación de variables o llamadas al sistema que generasen nuevos hilos. Lo que supone crear un \textit{\gls{parser}} para encontrar estas sentencias y añadir a continuación una función que almacene la variable y su valor en la función e hilo correspondiente. 

Sin embargo, el desarrollo del \textit{\gls{parser}} supone una gran complejidad debido a las numerosas sentencias que tener en cuenta, por lo que se decidió explorar nuevas alternativas.

\subsubsection{Uso de depuradores externos} \label{subsec:depuradores-externos}

Dado que implementar un depurador desde 0 supone una gran complejidad, se ha evaluado la opción de utilizar un depurador externo. Durante el \chapterref{estado-del-arte} se analizaron los depuradores existentes, dentro de estos depuradores tan solo GDB (\subsectionref{gdb}), LLDB (\subsectionref{lldb}) y RR (\subsectionref{rr}) permitían construir una aplicación sobre ellos. Aunque LLDB tenga una API en Python que permita la interactividad con la sesión de depuración, carece de la capacidad de rebobinar durante la depuración, tal y como indica el requisito \sreqref {FN-rebobinar}. Por lo tanto, RR es una opción más viable, que aunque no ofrezca una API en Python que permita la interactividad, sí que ofrece una interfaz máquina que ofrece una salida formateada.

No obstante, RR registra la ejecución del programa para reproducirla posteriormente, garantizando así una ejecución determinista. Esto limitaría la capacidad del usuario para modificar el flujo de ejecución a su conveniencia. Por ello, se ofrecerá la opción de elegir entre grabar la ejecución, permitiendo el rebobinado, o no grabarla (utilizando solo GDB), permitiendo una ejecución libre de los hilos.

\subsection{Sandbox} \label{subsec:sandbox}

Tal y como se indica en \sreqref{NF-sandbox}, el sistema debe de ejecutar el código en un entorno aislado para evitar problemas de seguridad o disponibilidad. Para ello, se optó por utilizar contenedores Docker en los que se ejecutarán los programas. De esta manera cualquier código malicioso no podrá acceder a los archivos del sistema ni atacar a la disponibilidad del servidor. Además se limitarán los recursos del contenedor para controlar el uso de los mismos.

La principal dificultad que supone incorporar contenedores es controlar la disponibilidad de cada uno de ellos. Las características del proyecto nos obligan a que la comunicación entre cliente y docker sea por sesión, lo que implica que durante la sesión el docker no estará disponible para servir a ningún otro cliente. Una posible solución es que la responsabilidad del servidor sea servir los ficheros estáticos del cliente y redirigir los mensajes del cliente al contenedor asociado a la sessión correspondiente y gestionar las comunicaciones entre clientes y contenedores. Esta solución podría generar un cuello de botella en el componente servidor en el caso de tener muchos clientes activos, dado que todas las comunicaciones pasarían por el servidor.

<IMAGEN DE PRIMERA APROXIMACION>

Es por esta razón que se ha tomado la decisión de quitar responsabilidad al servidor e incorporarla en los contenedores. El servidor se convertirá en un \textit{proxy} y se encargará de redirigir la conexión de un cliente a un docker disponible, es decir, solo tendrá información sobre a qué contenedor está conectado cada cliente. 
Cada docker alojará un pequeño servidor que sirva los ficheros estáticos y las funcionalidades de los requisitos.

<IMAGEN DE LA SOLUCION FINAL>

Es importante destacar, que como un contenedor puede dejar de estar disponible por un uso malicioso desde el lado cliente, el proxy debe de conocer la disponibilidad de cada uno de los contenedores. Para ello cada uno de los contenedores mandará latidos, de manera que el proxy pueda conocer qué dockers están disponibles.

Para conseguir todo esto se creará una imagen Docker que contenga el código correspondiente a la comunicación tanto con el cliente y con el proxy, el código de las funcionalidades del depurador y los ficheros estáticos a servir.
Cada uno de estos contenedores se levantará a través de \textit{Docker Compose}, configurado con un \texttt{docker-compose.yml} en el que se indicarán los puertos que cada docker tiene que mapear y las variables de entorno para las comunicaciones. 

Es por todo esto que la arquitectura distribuida final constará de uno o varios clientes, un único \textit{proxy}, al que se conectarán los clientes para ser redirigidos, y varios \textit{contenedores} que se encargarán de toda la lógica del sistema.

\subsection{Comunicación entre procesos} \label{subsec:comunicacion-procesos}

Dada la existencia de un cliente, un proxy y un contenedor, es necesario establecer una comunicación entre ellos. Esta comunicación se puede realizar de diferentes maneras, pero se han considerado las dos siguientes opciones: 

\begin{itemize}
    \item \textbf{REST}: Permite la comunicación entre procesos a través de peticiones HTTP. Esta comunicación es unidireccional, sin control de estados y se establece una conexión por cada petición. Es ideal para controlar una gran cantidad de comunicaciones y para servir unos recursos.
    \item \textbf{Web Sockets}: Esta comunicación es bidireccional, y permite el envío de mensajes en tiempo real. Es ideal para aplicaciones que requieren una comunicación constante.
\end{itemize}

Dadas las características de la aplicación, se optará por usar REST API para servir los ficheros estáticos y para enviar los latidos de los contenedores, se usará Web Sockets para la comunicación entre el cliente y su correspondiente contenedor, permitiendo entablar la sesión y que exista una comunicación bidireccional. 

\subsection{Lenguajes de Programación} \label{sec:programacion}

Dada la arquitectura distribuida del sistema, se necesita usar un lenguaje de programación para el lado cliente y otro para el lado servidor, correspondiente al proxy y los contenedores.

\subsubsection{Tecnologías del lado cliente} \label{subsubsec:tecnologias-cliente}

Para la construcción de la aplicación web se ha basará en HTML5 para dar estructura al código, CSS3 para dar estilos, y JavaScript para implementar las distintas funcionalidades. Se ha decidido elegir este \textit{Stack} por ser el más básico y el que más experiencia se tiene. Este \textit{Stack} será más que suficiente dado que el lado cliente no será de gran envergadura y no necesitará más que unos pocos botones, un editor de código y una comunicación a través de WebSockets.


\subsubsection{Tecnologías del lado servidor} \label{sec:tecnologias-servidor}

En cuanto al lenguaje de programación del lado servidor es necesario elegir un lenguaje que permita la implementación de WebSockets para la comunicación en tiempo real, una API REST para servir los ficheros estáticos y enviar los latidos, que trabaje con ficheros para la creación de ficheros con el código del usuario, que permita la concurrencia para poder gestionar procesos en paralelo, y que permita crear un proceso en el que ejecutar RR.
Dentro de las opciones destacan Python, Go, Rust y NodeJS, por lo que vamos a analizar cada una de ellas.

\begin{itemize}
    \item \textbf{Python}: Un lenguaje de programación interpretado, muy versátil, aunque con un rendimiento moderado. Gracias a frameworks como Flask para implementar APIs REST, aiohttp o FastAPI para WebSockets, y al módulo threading, para la concurrencia, es una opción viable.
    \item \textbf{Go}: Un lenguaje de programación compilado, con un buen rendimiento y orientado en la concurrencia y el procesamiento en la red. Su soporte nativo para WebSockets mediante goroutines, y frameworks como Gin o Echo para APIs REST lo hacen ideal para este tipo de comunicación.
    \item \textbf{Rust}: Un lenguaje de programación compilado, con un gran rendimiento, aunque con una curva de aprendizaje pronunciada. Tiene bibliotecas como Actix-web para APIs REST y WebSockets, pero no es la más recomendable por su complejidad. 
    \item \textbf{NodeJS}: Un lenguaje de programación interpretado con excelente soporte tanto para APIs REST (Express.js) como para WebSockets (Socket.io), aunque su concurrencia se basa en un solo hilo utilizando un bucle de eventos y un modelo asíncrono; lo que no es un paralelismo real. Su modelo no es ideal para operaciones intensivas en CPU.
\end{itemize}

Tanto Go como Python son lenguajes adecuados para el proyecto. Aunque Go ofrece un rendimiento superior, la disponibilidad de la biblioteca Python \textit{pygdbmi}, que facilita la gestión de una sesión RR/GDB y la obtención de la salida MI en formato JSON, convierte a Python en la opción más conveniente.

\section{Arquitectura del sistema}\label{sec:arquitectura-sistema}

Tal y como se ha comentado en \sectionref{estudio-solucion-final}, el sistema consta de tres partes: el cliente, el proxy y el contenedor docker, y cada uno de ellos consta de varios componentes. 

\begin{itemize}
    \item \textbf{Cliente}: Permite facilitar la interacción del usuario con el depurador, además de visualizar las salidas y cambios ocurridos durante la ejecución. En este componente se podrá escribir código, y comunicará las acciones al servidor para ejecutar las correspondientes funcionalidades. 
    Dentro de la aplicación web, existen dos componentes principales:

    \begin{itemize}
        \item \textbf{Intefaz Gráfica}: Su responsabilidad es actulizar la información que se muestra por pantalla-
        \item \textbf{Comunicación con el contenedor (Web Socket)}: Se encarga enviar y recibir mensajes del al contenedor.
        \item \textbf{Editor de Código} Su responsabilidad es permitir al usuario escribir el código que se va a depurar.
    \end{itemize}

    \item \textbf{Proxy}: Se encargará de gestionar la disponibilidad de los contenedores y los contenedores libres. Además redirigirá los clientes a los contenedores correspondientes.
    Este componente consta de dos componentes:
    \begin{itemize}
        \item \textbf{Gestión de Contenedores}: Al recibir una petición de un cliente se le redirigirá a un contenedor libre, este contenedor será asociado a este cliente hasta que se desconecte, por lo que dejará de estar libre.
        \item \textbf{Disponibilidad de Contenedores}: Alojará un servicio para escuchar los contenedores disponibles. Si tras cierto tiempo deja de recibir latidos de un contendor lo dará por muerto, por lo que no podrá ser asociado a nuevos clientes.  
    \end{itemize}

    \item \textbf{Contenedor Docker}: Se encarga de servir los ficheros estáticos al cliente y de ejecutar las funcionalidades pedidas por este.
    \begin{itemize}
        \item \textbf{Servicio de ficheros estáticos}: El contendor servirá el html, css y JavaScript del cliente al recibir una petición GET por parte del cliente.
        \item \textbf{Web Socket Docker}: El contenedor utilizará Web Socket para la comunicación con el cliente.
        \item \textbf{Funcionalidades de Compilación}
        \item \textbf{Funcionalidades de Depuración}: Este componente contendrá la implementación de las funcionalidades de depuración, las cuales serán llamadas a través de la API.
        \item \textbf{Envío de latidos}: El contenedor enviará latidos cada cierto tiempo.
    \end{itemize}
\end{itemize}

En la figura \ref{fig:componentes_TFG} se muestra el diagrama de componentes UML \cite{Cook2017} donde se pueden observar los distintos componentes y sus diferentes interfaces.

\drawiosvgfigure[0.7]{componentes_TFG}{Diagrama de componentes del sistema}

Para la especificación de los distintos componentes se ha usado la siguiente plantilla: 

\printcomptemplate
% ------- Lado Cliente -------
\begin{component}{Interfaz Gráfica}
{Mostrar la información actualizada al usuario por pantalla}
{COM-Editor de Código, COM-Web Socket Cliente} % dependencias
{Estado actual del sistema} % in-data
{NA} % out-data
{FN-GUI, FN-aviso-error-concurrencia, FN-visualizacion-variables, FN-visualizacion-hilos, FN-visualizacion-evolucion} % relations
La Interfaz Gráfica debe de gestionar la interacción del usuario con la aplicación y mostrar la información de manera estructurada y clara. %description 
\end{component}

\begin{component}{Editor de Código}
    {Permitir al usuario escribir el código que se va a depurar}
    {\NA} % dependencias
    {\NA} % in-data
    {Código escrito, estado del editor de código} % out-data
    {FN-GUI, FN-editor, FN-editor-breakpoint} % relations
    Este componente permitirá al usuario escribir código, colorear la sintaxis y gestionar de forma visual los breakpoints. %description
\end{component}

\begin{component}{Web Socket Cliente}
{Punto de comunicación por Web Socket desde el cliente al servidor}
{COM-Editor de Código, COM-Web Socket y REST API Servidor} % dependencias
{Mensajes del servidor} % in-data
{Cambios del sistema ,Mensajes del cliente} % out-data
{} % relations
La comunicación con el servidor se encargará de gestionar la comunicación entre el cliente y el servidor a través de Web Sockets. %description
\end{component}

% ------- Lado Proxy -------

\begin{component}{Gestión de Contenedores}
{Asignar clientes a contenedores libres}
{COM-Disponibilidad de Contenedores} % dependencias
{Contenedores Disponibles} % in-data
{URL para la conexión} % out-data
{\NA} % relations
Este componente asignará a un nuevo cliente un contenedor libre hasta que se desconecte. Al asignar a un contenedor le redireccionará al contenedor correspondiente %description
\end{component}

\begin{component}{Disponibilidad de Contenedores}
{Escucha latidos de los contenedores para comprobar su disponibilidad }
{COM-Gestión de Contenedores, COM-Envío de Latidos} % dependencias
{Latido} % in-data
{Contenedores Disponibles} % out-data
{\NA} % relations
Registra cada uno de los latidos escuchados por cada contenedor, si tras 10 segundos no ha recibido un latido dará por no disponible al contenedor %description
\end{component}

% ------ Lado Contenedor -------

\begin{component}{Web Socket Docker}
{Gestión de comunicación entre el contenedor y el cliente a través de Web Sockets}
{COM-Web Socket Cliente, COM-Funcionalidades Depuración} % dependencias
{Mensajes del cliente} % in-data
{Mensajes del contenedor} % out-data
{\NA} % relations
La comunicación con el contenedor se encargará de gestionar la comunicación entre el contenedor y el cliente a través de Web Sockets. %description 
\end{component}

\begin{component}{Funcionalidades Compilación}
{Se encarga de compilar el codigo recibido y ejecutarlo sin modo depuración}
{COM-Web Socket Docker}
{Código}
{Salida Estandar}
{FN-fichero-codigo, FN-compilacion, FN-ejecutar, FN-aviso-error-concurrencia}
Este componente se encarga de realizar acciones básicas que no están relacionadas directamente con la depuración, como compilar el código y ejecutarlo.
\end{component}

\begin{component}{Funcionalidades de Depuración}
{Gestionar la ejecución de las funcionalidades de depuración}
{COM-Web Socket Docker} % dependencias
{Funcionalidad a realizar} % in-data
{Estado tras la ejecución de la funcionalidad} % out-data
{FN-depurar, FN-step-over, FN-step-into, FN-step-out, FN-continuar-ejecucion, FN-rebobinar} % relations
Este componente ejecutará las funcionalidades del depurador y devolverá el resultado de aplicar esas funcionalidades %description
\end{component}

\begin{component}{Envío de Latidos}
{Envío de latidos}
{COM-Disponibilidad de Contenedores} % dependencias
{Latido} % in-data
{\NA} %out-data
{\NA} % relations
Envío de latidos cada 5 segundos a la dirección del proxy
\end{component}

\begin{component}{Servicio de Ficheros Estáticos}
{Envío de ficheros estáticos al cliente}
{\NA}
{Ficheros HTML, CSS y JavaScript}
{\NA} %relations
{Se encarga de envíar ficheros estáticos tras recibir una petición GET por parte del cliente para que este pueda acceder a su aplicación web}
\end{component}

\FloatBarrier

\subsubsection{Trazabilidad} {\label{subsubsec:trazabilidad-comp}}

\begin{table}[htb]
    \ttabbox[\FBwidth]
      {\caption{Trazabilidad de los componentes con los requisitos funcionales}\label{tab:trazabilidadCOM-FN}}
      {\traceabilityCompFN}
  \end{table}

